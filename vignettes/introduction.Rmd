---
title: "antigen.garnish: ensemble neoepitope prediction from DNA variants in R."
author: "Lee Richman, Andrew Rech"
date: "2/13/2018"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
library(antigen.garnish)
library(data.table)
library(magrittr)
library(ggplot2)
knitr::opts_chunk$set(cache = TRUE, dpi=360, eval = FALSE, error = FALSE, warning = FALSE, message = FALSE, comment = "#", cache.comments = FALSE, fig.align = "center")
```

# `antigen.garnish` vignette

Welcome to `antigen.garnish`! For installation instructions, workflow examples, and more information on the MHC binding prediction algorithms used by the package, please see the [README](https://github.com/andrewrech/`antigen.garnish`). `antigen.garnish` works for human and murine data only and requires internet access.

`antigen.garnish` is an R package that allows for ensemble neoantigen prediction and quality analysis from SNVs, indels, and fusions. `antigen.garnish` uses seven MHC binding affinity prediction algorithms, classifies neoepitopes by type (see `?garnish_summary`), and applies a neoantigen fitness model adapted from [*Lukza et al. 2017*](https://www.ncbi.nlm.nih.gov/pubmed/29132144). Supported input formats include VCFs, [JAFFA](https://github.com/Oshlack/JAFFA/wiki) output, and custom tables of either transcript or peptide level data. `antigen.garnish` does not perform variant calling nor MHC haplotyping. We recommend following the [GATK best practices for preprocessing for somatic variant calling](https://software.broadinstitute.org/gatk/best-practices/workflow?id=11146) and using at least two variant callers so that calls may be [intersected](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5394620/) by the `garnish_predictions` function. The package has been most thoroughly tested with output from [MuTect2](https://software.broadinstitute.org/gatk/documentation/tooldocs/3.8-0/org_broadinstitute_gatk_tools_walkers_cancer_m2_MuTect2.php) and [Strelka2](https://github.com/Illumina/strelka). For gene fusion analysis from RNAseq, please use [JAFFA](https://github.com/Oshlack/JAFFA/wiki) output and see `?garnish_jaffa`.

This vignette will cover the basic workflow of the package from each type of input, and highlight some of the output parameters that may be useful for prioritizing neoepitopes for further study or therapeutic targeting. An example analysis is provided using the supplementary data from [*Lukza et al. 2017*](https://www.ncbi.nlm.nih.gov/pubmed/29132144).

In addition to the main `garnish_predictions` function that passes peptides to the MHC binding prediction algorithms, user-friendly functions for sample-level analysis are provided: `garnish_plot` and `garnish_summary`. All functions in the package have associated manual pages with further details, for example `?garnish_predictions`.

## VCF input

The `garnish_variants` functions parses `vcf` and `vcf.gz` files using the [vcfR](https://cran.r-project.org/web/packages/vcfR/index.html) package. S ample names are determined by searching vcf headers for BAM file names. V cfs with identical sample names will be intersected when possible by default. We recommend intersecting variant calls to [improve sensitivity and minimize false positive variant calls](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5394620/). To take the union of `vcf` files with identical sample names, call the function with `intersect = FALSE`. See `?garnish_variants` for more information. For this reason, multi-sample vcfs must be split before passage to the function to be able to determine the source of the variant in the final output. Vcfs spread over multiple files should be concatenated into a single file or passsed with `intersect = FALSE`.

`vcf` input must be annotated with [SnpEff](http://snpeff.sourceforge.net/). A nnotations are used to identify which variants to keep. SNV and indel variants that will produce a change in predicted peptide sequence for the associated transcript will be returned in an output data table. Non-coding variants will be dropped. Transcript metadata and sequences are queried from [biomaRt](https://bioconductor.org/packages/release/bioc/html/biomaRt.html).


```{r getdt, include = FALSE}

dt <- "antigen.garnish_example.vcf" %T>%
      utils::download.file("http://get.rech.io/antigen.garnish_example.vcf", .) %>%

  # run test
    garnish_variants

file.remove("antigen.garnish_example.vcf")

```

```{r vcf, eval = FALSE}
# prepare vcf input from all vcfs in working directory
vcfs <- list.files(pattern = "\\.vcf(\\.gz)?$")
dt <- garnish_variants(vcfs)
```
```{r vcf2}
str(dt)
```

`garnish_variants` returns a data table object with one annotated variant per row and the columnns:

  - **sample_id**: sample identifier constructed from input \code{.bam} file names
  - **se**: SnpEff annotation
  - **effect_type**: SnpEff effect type
  - **ensembl_transcript_id**: transcript effected
  - **ensembl_gene_id**: gene effected
  - **protein_change**: protein change in [HGVS](http://varnomen.hgvs.org/recommendations/DNA/) format
  - **cDNA_change**: cDNA change in [HGVS](http://varnomen.hgvs.org/recommendations/protein/) format
  - **protein_coding**: is the variant protein coding?

To continue analysis of this input, please see the [**garnish_predictions**](#pred) section of this vignette.

## Gene fusions input

To evaluate novel peptides generated across the breakpoint of a predicted gene fusion, `garnish_jaffa` parses results from [JAFFA](https://github.com/Oshlack/JAFFA/wiki) run on RNAseq data. This function takes the fasta output of fusion reads and the output table of fusion predictions. For maximum confidence, only fusions that are predicted by JAFFA to align across exons, are in-frame, and are ranked Medium or High confidence are kept. The human or murine database to collect metadata from must be specificed in the function call with the `db` argument. See `garnish_jaffa` for more.

```{r jaffahide, include = FALSE}

path <- "antigen.garnish_jaffa_results.csv" %T>%
     utils::download.file("http://get.rech.io/antigen.garnish_jaffa_results.csv", .)
    fasta_path <- "antigen.garnish_jaffa_results.fasta" %T>%
      utils::download.file("http://get.rech.io/antigen.garnish_jaffa_results.fasta", .)

  # get predictions
dt <- antigen.garnish::garnish_jaffa(path, db = "GRCm38", fasta_path)

```
```{r jaffa, eval = FALSE}

dt <- garnish_jaffa(path = "jaffa_results.csv",
                    db = "GRCm38",
                    fasta_path = "jaffa_results.fasta")

```
```{r jaffashow}
# lets take a peek
str(dt)
```

To continue analysis of this input, please see the [**garnish_predictions**](#pred) section of this vignette.

## Other input

Direct peptide or transcript input with MHC alleles to `garnish_predictions` is supported. See the example below and `?garnish_predictions` for more information.

Peptide level direct input, either a data.table or data.frame in R or a file path with structure:

```{r otherpep, echo = FALSE}

data.table::data.table(sample_id = "sample_1",
                       pep_mut = c("MTEYKLVVVDAGGVGKSALTIQLIQNHFV", "SIINFEKLANTIGENGARNISHFDT"),
                        mutant_index = c(15, "all"), MHC = c("HLA-A*02:01",
                                                   "H-2-Kb H-2-IAb"))

```

Transcript level input, requires Ensembl Transcript ID without version number appended:

```{r othert, echo = FALSE}

data.table::data.table(sample_id = "sample_1",
                       ensembl_transcript_id = c("ENST00000311936", "ENSMUST00000032399"),
                        cDNA_change = c("c.718T>A","c.35G>T"), MHC = c("HLA-DRB1*11:07",
                                                   "H-2-Kb H-2-IAb"))

```

In these tables, `mutant_index` indicates the position of the mutated amino acid in the sequence. This is the anchor point for the 9:15mer sliding window that `garnish_predictions` will use to generate nmers to pass to the prediction algorithms. If set to "all", then the sliding window will generate nmers across the entire sequence, using each residue as an anchor point.  `garnish_predictions` will still remove redundant peptides generated in this manner and peptides matching the wild-type peptidome.

To continue analysis of this type of input, please see the [**garnish_predictions**](#pred) section of this vignette. Because these tables already contain MHC allele information, the step to add MHC should be skipped before continuing the analysis.

## garnish_predictions

In order to pass peptides to the seven prediction algorithms, MHC haplotypes must be provided for each sample. To see proper formatting and supported MHC alleles:
```{r mhclist}
mhcdt <- list_mhc()

# lets look at all the class I mouse alleles supported and their syntax

mhcdt[species == "mouse" & class == "I"] %>% print

```

If using direct input to `garnish_predictions` with tables containing MHC alleles already, you may skip this step.

`garnish_predictions` will also recognize "all" as an MHC type and will predict peptides across all supported alleles. This can be very computationally demanding so it is not recommended for a large number of samples or variants unless working on a cluster. Multiple MHC alleles for a single sample should be entered as a space separated string, e.g. "H-2Kb H-2-Db H-2-IAb". To ensure the correct IEDB file is chosen later on for immune fitness modeling, separate rows of space separated strings for murine and human alleles must be used, even if the sample_id is the same.

```{r addmhc}

# add the MHC manually in R using data.table syntax
dt[, MHC := "H-2Kb H-2-Db H-2-IAb"]

str(dt)

```

```{r mhc2, eval = FALSE}

# alternatively, a table with columns "sample_id" and "MHC" can be read into R and merged

mhcdt <- rio::import("my_mhctable.xlsx") %>% data.table::as.data.table

dt <- merge(dt, mhcdt, by = c("sample_id", "MHC"))

```

```{r getpdt, include = FALSE}

pdt <- data.table::fread("http://get.rech.io/antigen.garnish_example_output.txt") %>%
  .[, fitness_score := 4.2]

```

After MHC alleles have been added for all sample_ids, `garnish_predictions` will generate all possible novel 8-15mers generated by input variants. Peptides are checked against the wild-type human or mouse peptidomes, using a dataset from UniProt. Peptides derived from variants that match a wildtype sequence regardless of origin are dropped from further analysis (unless `remove_wt` is set to false). By default, the [NCBI BLAST command line tool](https://blast.ncbi.nlm.nih.gov/Blast.cgi) is then used to query for wild-type near matches for frameshift and fusion proteins, as well as against the [IEDB](http://www.iedb.org/database_export_v3.php). Mutant peptides are matched to their wild-type and iedb counterparts by unique ids before passing to prediction algorithms. In the final output, the `min_DAI` value will represent the differential binding between the mutant nmer and any wild-type single nucleotide mismatch in the appropriate reference proteome. In addition, `iedb_score` represents the sum of all binding energies from IEDB positive T-cell assay alignment results as estimated by Smith-Waterman alignment using BLOSUM62 (from `Biostrings`) and using the same formulae reported in [*Lukza et al. 2017*](https://www.ncbi.nlm.nih.gov/pubmed/29132144) translated into R.  The `min_DAI` and `iedb_score` are then multiplied to derive the `fitness_score` for each nmer, analogous to the "NeoantigenRecognitionPotential" derived from the original source code distributed with that paper.

MHC prediction algorithms used by `antigen.garnish` include [mhcflurry](https://github.com/hammerlab/mhcflurry), [mhcnuggets](https://github.com/KarchinLab/mhcnuggets), [netMHC](http://www.cbs.dtu.dk/services/NetMHC/), [netMHCII](http://www.cbs.dtu.dk/services/NetMHCII/), [netMHCpan](http://www.cbs.dtu.dk/services/NetMHCpan/) and [netMHCIIpan](http://www.cbs.dtu.dk/services/NetMHCIIpan/i). Peptides are passed to all possible prediction algorithms for all supported permutations of alleles and peptide lengths. In the case of netMHC algorithms, the "pan" version of the algorithm is only used if the more accurate base version does not return a prediction.

The returned binding affinities are then averaged together to generate the `Consensus_scores`. A  95% confidence interval based on the t-distribution is provided when at least 3 unique predictions are available.

If `fitness = TRUE` is passed to the function (default behavior), then an immune fitness model adapted from the python scripts provided in "SupplementaryDataFile7" of [*Lukza et al. 2017*](https://www.ncbi.nlm.nih.gov/pubmed/29132144). These scripts were adapted to allow predictions on peptides from 9:15 amino acids in length, but are otherwise unedited. The "R" component of this model, the TCR recognition probability, is then combined with the Differential Agretopicity Index (see [*Rech et al. 2018*](https://www.ncbi.nlm.nih.gov/pubmed/29339376) and `?garnish_summary`), or BLAST_A value when DAI is unavailable (such as for frameshifts and fusions or with direct peptide input to `garnish_predictions`), to generate a `fitness_score` for each peptide. See the [example analysis](#ex) below for a comparison of `antigen.garnish` `fitness_score` and "Neoantigen Recognition Potential" as published in the original paper.

```{r predict, eval  = FALSE}

# run prediction tools and fitness model

pdt <- garnish_predictions(dt)

```

```{r showpredict}
dim(pdt)

# large table so lets just look at the columns
names(pdt)
```

The resulting table will contain:

 * **pep_type**: type of peptide
 * **pep_mut**: mutant peptide sequence
 * **pep_wt**: wt peptide sequence
 * **mismatch_s**: starting index of mutant peptide sequence
 * **mismatch_l**: ending index of mutant peptide sequence
 * **mutant_index**: index of mutant peptide
 * **nmer**: nmer for prediction
 * **nmer_i**: index of nmer in sliding window
 * **_net**: netMHC prediction tool output
 * **mhcflurry_**: mhcflurry prediction tool output
 * **mhcnuggets_**: mhcnuggets prediction tool output
 * **Consensus\_scores**: Average value of MHC binding affinity from all prediction tools that contributed output. 95\% confidence intervals are given by `Upper_CI`, `Lower_CI`.
 * **DAI**: Differential agretopicty index, see `garnish_summary` for an explanation of DAI.
 * **BLAST_A**: Ratio of consensus binding affinity of mutant peptide / closest single AA mismatch from blastp results. Returned only if `blast = TRUE`.

Fitness model results:

 * **ResidueChangeClass**: Amino acid change class, eg hydrophobic to non-hydrophobic.
 * **A**: Component of the fitness model. Differential MHC affinity of mutant and closest wt peptide, equivalent to DAI if available, otherwise uses BLAST_A.
 * **R**: TCR recognition probability, determined by comparison to known epitopes in the IEDB and amino acid properties.
 * **fitness_score**: Product of A and R. The peptide with the highest value per sample is the dominant neoepitope.

If transcript-level input is provided:

 * **cDNA_seq**: mutant cDNA sequence
 * **cDNA_locs**: starting index of mutant cDNA
 * **cDNA_locl**: ending index of mutant cDNA
 * **frameshift**: frameshift variant?
 * **coding**: wt cDNA sequence
 * **coding_mut**: mutant cDNA sequence

We will next demonstrate two useful sample-level summary functions for antigen.garnish output.

## Integration of RNA Expression

Many investigators are interested in using RNA expression data as a method to filter for "expressed" variants. Because RNA expression data is highly variable by the experimental conditions under which is collected and the ability to distinguish variant transcripts from sequencing error is often poor, the *in vivo* relevance of this filtering is unclear. Nevertheless, we provide sample code to filter `antigen.garnish` output using a count matrix.

```{r RNA, eval = FALSE}

# filter for expressed variants using a count matrix file where first column is ensembl transcript or gene id's and other columns are counts
# column names must match sample_id names in antigen.garnish output
mat <- "my_count_matrix.xlsx"
dt <- "ag_output.txt"

garnish_rna_filter <- function(dt, mat, min_counts = 10){

  require("magrittr")
  require("data.table")

  mat <- mat %>% rio::import %>% data.table::as.data.table

  dt <- dt %>% rio::import %>% data.table::as.data.table

  mat %>% data.table::setnames(names(mat)[1], "id")

  mat %<>% melt(id.vars = "id",
                variable.name = "sample_id",
                value.name = "counts")

  mat <- mat[counts > min_counts, id %>% unique, by = "sample_id"]

  col <- "ensembl_transcript_id"

  if (mat[, id][1] %like% "ENS(MUS)?G") col <- names(dt)[which(names(dt) %like% "ensembl_gene_id")] %>% .[1]

  mat %>% data.table::setnames("id", col)

  dt <- merge(dt, mat, by = names(mat))


  return(dt)

}

# filter by 20 counts per transcript or gene by sample and save to disk

garnish_rna_filter(dt, mat, min_counts = 20) %>%
  data.table::fwrite("ag_output_rna_filt.txt", sep = "\t", quote = FALSE, row.names = FALSE)

```

## Summarizing Output

Sample-level summary analysis of `garnish_predictions` results is performed by the `garnish_summary` function. This allows for a quick analysis of overall neoepitope burden by neoepitope class, MHC class, and type of variant.

```{r summ}

sdt <- garnish_summary(pdt)

print(sdt)

```

Simple column graphs including overall neoepitope burden, breakdown by affinity, and top 3 scores (see `?garnish_summary`) can be produced and saved to the working directory.

```{r plot}

garnish_plot(pdt)

list.files(pattern = "antigen.garnish.*\\.pdf$")

```

Here are some example plots:

![](http://get.rech.io/ag_plots_example.png)

## Analysis Example

In this example, we will import the data from [*Lukza et al. 2017*](https://www.ncbi.nlm.nih.gov/pubmed/29132144), modified to conform to the necessary input format of antigen.garnish. We will then summarize and plot the data, and show the concordance of `fitness_score` and their reported "NeoantigenRecognitionPotential".

```{r readin, eval = FALSE}

dt <- data.table::fread("http://get.rech.io/Lukza_input.txt")

head(dt)

# now we need to subset the data into the minimum columns required for prediction and rename them appropriately

dti <- dt[, .SD, .SDcols = c("Sample", "MT.Peptide", "WT.Peptide", "MT.Allele")] %>%
          data.table::setnames(c("Sample", "MT.Peptide", "MT.Allele"),
                               c("sample_id", "pep_mut", "MHC"))

# lets take a random sample of 1,000 rows to make this smaller
set.seed(42)

dts <- dti[sample(1:nrow(dti), size = 1000)]


# function to identify mutant index from this input

get_mi <- function(a,b){

  a %<>% strsplit(split = "") %>% unlist
  b %<>% strsplit(split = "") %>% unlist

  return(which(a != b))

}

dts[, mutant_index := get_mi(pep_mut, WT.Peptide), by = 1:nrow(dts)]

# fix MHC syntax to conform with antigen.garnish requirements
dts[, MHC := MHC %>% paste(" HLA-", ., sep = "")] %>%  
      .[, MHC := paste(
        stringr::str_extract(MHC, pattern = "HLA-[ABCE]"),
        "*",
        stringr::str_extract(MHC, pattern = "(?<=(HLA-[ABCE]))[0-9]{2}"),
        ":",
        stringr::str_extract(MHC, pattern = "[0-9]{2}$"),
        sep = "")]

# This only includes 9mer input, so will trigger warnings about no 10-15mers for modeling, please ignore
dto <- garnish_predictions(dts)

# keep only 9mers for comparison and remove NA values from fitness_score
dto <- dto[nchar(nmer) == 9 & !is.na(fitness_score)]

# read in the output from the paper
fit_dt <- data.table::fread("http://get.rech.io/Lukza_output.txt")

# prep tables for merging
fit_dt <- fit_dt[, source := source %>% stringr::str_extract("VanAllen|Rizvi|Snyder")] %>%
      .[Excluded == FALSE] %>%
        data.table::setnames(c("Sample", "MutatedPeptide", "MutantPeptide"),
                              c("sample_id", "mutant_index", "nmer"))
dto[, MHC := MHC %>% stringr::str_replace_all("\\*|:|HLA-", "")]

for (i in dto[, blast_uuid %>% unique])
  dto[blast_uuid == i, WildtypePeptide := dto[blast_uuid == i & pep_type == "wt", nmer]]

mdt <- merge(
            fit_dt,
            dto[, .SD, .SDcols = c("var_uuid", "sample_id", "nmer",
                                    "mutant_index", "fitness_score",
                                    "ResidueChangeClass", "WildtypePeptide",
                                    "A", "R", "Consensus_scores")],
            by = c("sample_id", "nmer", "mutant_index", "ResidueChangeClass", "WildtypePeptide", "R"))

# model was designed for cutoff of 500nM
mdt <- mdt[Consensus_scores < 500]

# lets check the correlation with simple linear regression
lm <- stats::lm(NeoantigenRecognitionPotential ~ fitness_score, mdt)

slm <- summary(lm)

print(slm)

# lets make a nice theme and plot it
custom_theme <- ggplot2::theme_bw() + ggplot2::theme_classic() +
                ggplot2::theme(text = ggplot2::element_text(size = 28),
                plot.title = ggplot2::element_text(face = "bold",
                hjust = 0.5, size = ggplot2::rel(0.5)), axis.text.y = ggplot2::element_text(size = ggplot2::rel(0.7),
                angle = 30, color = "black", face = "bold"),
                axis.text.x = ggplot2::element_text(size = ggplot2::rel(0.8),
                angle = 30, color = "black", hjust = 0.96, face = "bold"),
                axis.title.x = ggplot2::element_text(size = ggplot2::rel(0.6),
                face = "bold"), axis.title.y = ggplot2::element_text(size = ggplot2::rel(0.6),
                face = "bold"))

pval <- slm$coefficients[2,4] %>% signif(digits = 3)
if (pval == 0) pval <- "< 0.001"

ggplot(mdt, aes(x = fitness_score, y = NeoantigenRecognitionPotential)) +
geom_point(col = "dodgerblue") +
geom_abline(intercept = 0,
            slope = 1, linetype = "dashed") +
annotate("label", label = paste("r^2 = ", slm$adj.r.squared %>% signif(digits = 2), "\n",
                                "p = ", pval, sep = ""),
                                x = 1e-19, y = 1, fontface = "bold", size = 6) +
custom_theme +
scale_x_log10() + scale_y_log10() +
ggtitle("antigen.garnish fitness_score comparison")

```
Here is the correlation plot without subsampling:
![](http://get.rech.io/ag_score_comp.png)

```{r cleanup, include = FALSE}

list.files(pattern = "antigen.garnish.*\\.pdf$") %>% file.remove

c("antigen.garnish_jaffa_results.csv", "antigen.garnish_jaffa_results.fasta") %>% file.remove

```

## Parallelization

antigen.garnish source code is already highly parallelized through the use of the inherently parallelized [data.table](http://github.com/Rdatatable/data.table) R package whenever possible. Other function calls in the package are frequently wrapped in `mclapply` from the "parallel" package included in base R. For information on how to set the maximum number of cores to use, see `?mclapply`. Variants are passed to MHC prediction algorithms via `system` calls and therefore memory management may be a significant issue. Minmize parallelization if memory capacity is limited, `mclapply` returns errors, or prediction algorithms report segmentation fault errors.

```{r session}
sessionInfo()
```
